# project/inference.py
"""
InferÃªncia para anÃ¡lise de sentimentos (4 emojis).
Exponibiliza a funÃ§Ã£o predict_proba(text: str) -> dict no formato:

{
  "scores": {"ðŸ™‚":0.12,"ðŸ˜•":0.08,"ðŸ˜¡":0.25,"ðŸ˜¢":0.55},
  "label_top":"ðŸ˜¢",
  "score_top":0.55
}

- Carrega vectorizer.pkl e model.pkl de models/classic/
- DetecÃ§Ã£o leve de idioma: heurÃ­stica para PT-BR (log de aviso se suspeitar nÃ£o-PT)
- Log de tempo de inferÃªncia no console (objetivo < 300 ms em frases curtas)
"""

from __future__ import annotations

import os
import time
from typing import Dict

import numpy as np
from joblib import load

ALLOWED_LABELS = ["ðŸ™‚", "ðŸ˜•", "ðŸ˜¡", "ðŸ˜¢"]
VECTORIZER_PATH = os.path.join("models", "classic", "vectorizer.pkl")
MODEL_PATH = os.path.join("models", "classic", "model.pkl")

_VECTOR = None
_MODEL = None


def _lazy_load():
    global _VECTOR, _MODEL
    if _VECTOR is None:
        if not os.path.exists(VECTORIZER_PATH) or not os.path.exists(MODEL_PATH):
            raise FileNotFoundError(
                "Artefatos nÃ£o encontrados. Rode 'python train.py' para treinar e salvar os modelos."
            )
        _VECTOR = load(VECTORIZER_PATH)
        _MODEL = load(MODEL_PATH)


def _likely_pt_br(text: str) -> bool:
    """
    HeurÃ­stica simples e leve (sem dependÃªncias externas):
    - presenÃ§a de caracteres tÃ­picos (Ã£, Ãµ, Ã§) OU
    - presenÃ§a de palavras muito comuns do PT-BR.
    """
    t = text.lower()
    specials = any(ch in t for ch in ("Ã£", "Ãµ", "Ã§"))
    common_words = sum(w in t for w in [" de ", " que ", " nÃ£o ", " Ã© ", " para ", " com ", " estou ", " muito "])
    return specials or (common_words >= 1)


def predict_proba(text: str) -> Dict:
    """
    Executa inferÃªncia e retorna dicionÃ¡rio com scores por emoji, label_top e score_top.
    """
    _lazy_load()

    t0 = time.perf_counter()

    # DetecÃ§Ã£o leve de idioma
    if not _likely_pt_br(text):
        print("[AVISO] Texto possivelmente nÃ£o estÃ¡ em PT-BR. Prosseguindo mesmo assim.")

    X = _VECTOR.transform([text])
    proba = _MODEL.predict_proba(X)[0]  # array de probs na ordem de classes do modelo

    # Mapear para ALLOWED_LABELS na mesma ordem em que o modelo foi treinado.
    # LogisticRegression.classes_ mantÃ©m a ordem das classes vistas no treino.
    ordered_labels = list(_MODEL.classes_)
    # Converter para dict com as 4 chaves-emoji exatas
    scores = {lbl: float(proba[i]) for i, lbl in enumerate(ordered_labels)}

    # Garantir que todas as 4 chaves existam (em tese jÃ¡ existem)
    for emj in ALLOWED_LABELS:
        scores.setdefault(emj, 0.0)

    # Top-1
    label_top = max(scores.items(), key=lambda kv: kv[1])[0]
    score_top = scores[label_top]

    elapsed_ms = (time.perf_counter() - t0) * 1000
    print(f"[INFERÃŠNCIA] Tempo: {elapsed_ms:.2f} ms | Top: {label_top} ({score_top:.4f})")

    return {
        "scores": scores,
        "label_top": label_top,
        "score_top": float(score_top),
    }


if __name__ == "__main__":
    # Teste rÃ¡pido
    example = "Estou muito feliz com o resultado! ðŸŽ‰"
    print(predict_proba(example))
