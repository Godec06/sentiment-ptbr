# Analisador de Sentimentos em PortuguÃªs com Emojis ğŸ™‚ ğŸ˜• ğŸ˜¡ ğŸ˜¢

Projeto de **anÃ¡lise de sentimentos em portuguÃªs** usando emojis como rÃ³tulos.  
O modelo recebe uma frase (com ou sem emojis) e retorna a probabilidade de ela
estar associada a quatro emoÃ§Ãµes:

- ğŸ™‚ Feliz  
- ğŸ˜• Confuso  
- ğŸ˜¡ Bravo  
- ğŸ˜¢ Triste  

A ideia Ã© lidar com linguagem informal em PT-BR (gÃ­rias, xingamentos, abreviaÃ§Ãµes)
e mostrar claramente qual emoÃ§Ã£o Ã© mais provÃ¡vel para cada texto.

---

## 1. VisÃ£o geral

Este repositÃ³rio contÃ©m:

- pipeline de preparaÃ§Ã£o de dados a partir de planilhas Excel com textos e emojis;
- treinamento de modelos de machine learning clÃ¡ssicos (usando `scikit-learn`);
- scripts de inferÃªncia para testar frases;
- uma interface construÃ­da em Python (Streamlit) para digitar frases e visualizar
  as probabilidades por emoÃ§Ã£o.

---

## 2. Estrutura do projeto

```text
.
â”œâ”€â”€ app.py                  # Interface (Streamlit)
â”œâ”€â”€ inference.py            # FunÃ§Ãµes de inferÃªncia / prediÃ§Ã£o
â”œâ”€â”€ train.py                # Script de treino do modelo clÃ¡ssico
â”œâ”€â”€ README.md
â”œâ”€â”€ requirements.txt
â”œâ”€â”€ data/
â”‚   â”œâ”€â”€ raw/                # dados brutos (ex: treino.xlsx) - nÃ£o versionados
â”‚   â”œâ”€â”€ external/           # dados externos (ex: dataset_sentimentos_pt_200k.xlsx)
â”‚   â””â”€â”€ processed/
â”‚       â””â”€â”€ treino_clean.parquet   # dataset limpo (gerado no treino)
â””â”€â”€ models/
    â””â”€â”€ classic/
        â”œâ”€â”€ vectorizer.pkl         # vetorizador treinado (TF-IDF, etc.)
        â””â”€â”€ model.pkl              # modelo de classificaÃ§Ã£o treinado
```

## 3. Dataset


3. Dataset
Os dados sÃ£o montados a partir de frases em portuguÃªs associadas a emojis.
Cada linha do dataset final contÃ©m, por exemplo:

texto: mensagem em portuguÃªs

emoji: ğŸ™‚ ğŸ˜• ğŸ˜¡ ğŸ˜¢

label: classe de sentimento correspondente (feliz, confuso, bravo, triste)

Os arquivos principais usados no projeto sÃ£o:

data/raw/treino.xlsx

data/external/dataset_sentimentos_pt_200k.xlsx

O script de treino unifica, limpa e salva uma versÃ£o consolidada em
data/processed/treino_clean.parquet.

4. Como rodar o projeto
4.1. Clonar o repositÃ³rio

Copiar cÃ³digo

```
git clone https://github.com/Godec06/sentiment-ptbr.git
cd sentiment-ptbr
```

4.2. Criar ambiente virtual (opcional, mas recomendado)

Copiar cÃ³digo
```
python -m venv .venv

# Windows
.venv\Scripts\activate

# Linux / Mac
source .venv/bin/activate
```

4.3. Instalar dependÃªncias

Copiar cÃ³digo
```
pip install -r requirements.txt
```

5. Treinar o modelo
Coloque seus arquivos de dados em:

data/raw/treino.xlsx
data/external/dataset_sentimentos_pt_200k.xlsx

Depois rode:

Copiar cÃ³digo
```
python train.py --epochs 20 --batch-size 4096 --shuffle
```
O script vai:

carregar os datasets;

limpar e unificar os textos;
salvar data/processed/treino_clean.parquet;
treinar um modelo clÃ¡ssico (usando scikit-learn);
salvar o vetorizador e o modelo em:
models/classic/vectorizer.pkl
models/classic/model.pkl.

6. Fazer prediÃ§Ãµes
Depois de treinar, vocÃª pode testar o modelo de duas formas.

6.1. Usando inference.py direto

Copiar cÃ³digo
```
python inference.py
```
O script vem com alguns exemplos de frase e imprime as probabilidades
para cada emoÃ§Ã£o no terminal.

6.2. Usando as funÃ§Ãµes de Python

Copiar cÃ³digo
```
python - << "EOF"
from inference import predict_proba

texto = "Eu te adoro, vocÃª Ã© incrÃ­vel! â¤ï¸"
probs = predict_proba(texto)
print(probs)
EOF
```
A funÃ§Ã£o retorna um dicionÃ¡rio com as probabilidades para cada classe.

7. Interface web (Streamlit)
Para abrir a interface grÃ¡fica:


Copiar cÃ³digo
```
streamlit run app.py
```

A interface permite:


digitar frases em PT-BR;

visualizar as probabilidades para ğŸ™‚ ğŸ˜• ğŸ˜¡ ğŸ˜¢;

destacar a emoÃ§Ã£o mais provÃ¡vel;

inspecionar a saÃ­da em formato JSON.

8. PrÃ³ximos passos
Algumas ideias de evoluÃ§Ã£o do projeto:

ampliar e balancear ainda mais o dataset de treinamento;

testar modelos baseados em embeddings / deep learning;

adicionar mÃ©tricas detalhadas (F1 por classe, matriz de confusÃ£o, etc.);

publicar a interface em um serviÃ§o online (ex.: Streamlit Cloud).

9. Autor
Pedro Godec
AnÃ¡lise de Dados, BI & IA â€¢ IntegraÃ§Ãµes com n8n & CRMs
LinkedIn
